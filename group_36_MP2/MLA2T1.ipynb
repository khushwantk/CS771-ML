{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRz-TnmWi4on"
   },
   "source": [
    "## Group 36 - Task 1\n",
    "\n",
    "### Paths to change\n",
    "1. train_paths and eval_paths in cell 4 with dataset paths properly\n",
    "2. train_paths, eval_paths, feature_cache.pth, eval_feature_cache.pth paths in cell 6 with dataset paths properly\n",
    "\n",
    "feature_cache.pth and eval_feature_cache.pth files will be generated by feature extrction in cell4.\n",
    "\n",
    "We have explicitly provided link to these files to use directly avaoiding cell4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1i9MIWXXD87l",
    "outputId": "df370f5b-b400-4553-92f3-5bc55dc7ec62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.models import efficientnet_b3\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torchvision.models import efficientnet_b3\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "print(\"All packages imported successfully!\")\n",
    "import warnings\n",
    "# Suppress specific warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.utils.data.dataloader\")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=r\"You are using `torch.load` with `weights_only=False`.*\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4solZKRKVFNq",
    "outputId": "3ce98ed5-d5ab-4266-d729-195f11a71d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7Fpk_QncVHUO"
   },
   "outputs": [],
   "source": [
    "# Feature Extractor - EfficientNet_B3\n",
    "\n",
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "\n",
    "# EfficientNet feature extractor\n",
    "def initialize_feature_extractor():\n",
    "    # model = efficientnet_b3(pretrained=True)\n",
    "    model = efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "# Extract features using EfficientNet\n",
    "def extract_features(data, feature_extractor, batch_size=32):\n",
    "    transform = get_transform()\n",
    "    images = data['data']  # Assumed to be a numpy array\n",
    "    labels = torch.tensor(data['targets']) if 'targets' in data else None\n",
    "    transformed_images = [transform(Image.fromarray(img)) for img in images]\n",
    "    transformed_images = torch.stack(transformed_images)  # Stack them into a tensor\n",
    "\n",
    "    # dataset = TensorDataset(transformed_images, labels)  # TensorDataset to\n",
    "    if labels is not None:\n",
    "        dataset = TensorDataset(transformed_images, labels)  # Dataset with images and labels\n",
    "    else:\n",
    "        dataset = TensorDataset(transformed_images)  # Dataset with images only\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch  in tqdm(dataloader, desc=\"Extracting Features \"):\n",
    "            if labels is not None:\n",
    "                images, batch_labels = batch\n",
    "                all_labels.append(batch_labels)  # Collect labels\n",
    "            else:\n",
    "                images = batch[0]\n",
    "            images = images.to(device)\n",
    "            feats = feature_extractor(images).view(feature_extractor(images).size(0), -1)  # Flatten the features\n",
    "            features.append(feats.cpu().numpy())\n",
    "            # labels.append(_.cpu())\n",
    "    features = np.concatenate(features)\n",
    "    all_labels = np.concatenate(all_labels) if labels is not None else None\n",
    "    return features, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHXw2QEEVNYS",
    "outputId": "291b6e4f-c218-4c85-8f69-5832b9c9cda7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 3 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 4 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 5 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 6 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 7 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 8 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 9 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 10 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval set 1 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval set 2 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval set 3 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval set 4 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval set 5 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval set 6 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval set 7 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval set 8 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval set 9 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval set 10 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction - Will save 2 files features_cache1.pth and eval_features_cache1.pth\n",
    "# These files will be later imported by our code\n",
    "\n",
    "# We have already provided the extracted features and can use them directly skipping this cell\n",
    "\n",
    "\n",
    "features_cache = {}\n",
    "eval_features_cache = {}\n",
    "\n",
    "train_paths = [\n",
    "    f\"dataset/part_one_dataset/train_data/{i}_train_data.tar.pth\" for i in range(1, 11)\n",
    "]\n",
    "eval_paths = [\n",
    "    f\"dataset/part_one_dataset/eval_data/{i}_eval_data.tar.pth\" for i in range(1, 11)\n",
    "]\n",
    "feature_extractor = initialize_feature_extractor()\n",
    "\n",
    "for i in range(10):\n",
    "  print(f\" Precomputing features for training dataset D{i+1} : \")\n",
    "  if i not in features_cache:\n",
    "    current_data = torch.load(train_paths[i])\n",
    "    current_features,current_targets = extract_features(current_data, feature_extractor)\n",
    "    features_cache[i] = (current_features, current_targets)  # Cache features for the dataset\n",
    "\n",
    "for j in range(10):\n",
    "  print(f\"Precomputing features for Eval dataset D{j+1} : \")\n",
    "  if j not in eval_features_cache:\n",
    "    eval_data = torch.load(eval_paths[j])\n",
    "    eval_features,eval_targets = extract_features(eval_data, feature_extractor)\n",
    "    eval_features_cache[j] = (eval_features, eval_targets)\n",
    "\n",
    "\n",
    "torch.save(features_cache, \"features_cache1.pth\")\n",
    "torch.save(eval_features_cache, \"eval_features_cache1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pHMPGq96PCR-"
   },
   "outputs": [],
   "source": [
    "def update_lwp(features, labels, last_model=None):\n",
    "    if last_model is None:\n",
    "      prototypes = {}\n",
    "      class_counts ={}\n",
    "    else:\n",
    "      prototypes = last_model[0]\n",
    "      class_counts = last_model[1]\n",
    "\n",
    "    # Iterate over each unique class in the current dataset\n",
    "    classes = np.unique(labels)\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "\n",
    "\n",
    "    for cls in classes:\n",
    "        # Get the indices of the samples belonging to this class\n",
    "        class_indices = np.where(labels == cls)[0]\n",
    "\n",
    "        # Calculate the mean of the features for this class\n",
    "        class_features = features[class_indices]\n",
    "        new_mean = class_features.mean(axis=0)\n",
    "\n",
    "        # Update the prototypes using averaging\n",
    "        if cls in prototypes:\n",
    "            old_prototype = prototypes[cls]\n",
    "            old_count = class_counts[cls]\n",
    "            new_count = len(class_indices)\n",
    "            updated_prototype = (old_prototype  + new_mean ) / 2\n",
    "\n",
    "            prototypes[cls] = updated_prototype\n",
    "            class_counts[cls] += new_count  # Update the count of samples for this class\n",
    "        else:\n",
    "        # If it's the first time this class is seen, just store the new mean\n",
    "            prototypes[cls] = new_mean\n",
    "            class_counts[cls] = len(class_indices)\n",
    "\n",
    "    return prototypes, class_counts\n",
    "\n",
    "\n",
    "\n",
    "# Predict using the LwP\n",
    "def predict_lwp(features, prototypes):\n",
    "    distances = np.stack([np.linalg.norm(features - proto, axis=1) for proto in prototypes.values()], axis=1)\n",
    "    return np.argmin(distances, axis=1)\n",
    "\n",
    "# Self-training process\n",
    "def task1(train_paths, eval_paths,features_cache,eval_features_cache):\n",
    "    accuracies = np.zeros((10, 10))  # Accuracy matrix (10x10)\n",
    "    models=[]\n",
    "\n",
    "    # Predicting for all other datasets (D2, D3, ..., D10) and updating LwP\n",
    "    for i in range(1, 11):\n",
    "        print(f\"Working for f{i}\")\n",
    "\n",
    "        # Loading and Feature Extraction od Dataset i\n",
    "        current_features, current_targets = features_cache[i-1]\n",
    "\n",
    "        if i > 1:\n",
    "          # Predicted Labels\n",
    "            predicted_labels = predict_lwp(current_features, prototypes)\n",
    "            # Update the model\n",
    "            prototypes, class_counts = update_lwp(current_features, predicted_labels, models[-1])\n",
    "        else:\n",
    "          # Only for D1 as it is already labelled\n",
    "            predicted_labels = current_targets\n",
    "            # Train F1\n",
    "            prototypes, class_counts = update_lwp(current_features, predicted_labels)\n",
    "\n",
    "\n",
    "        # print(class_counts)\n",
    "        models.append((prototypes,class_counts))\n",
    "\n",
    "\n",
    "        # Evaluate the model on all relevant held-out datasets\n",
    "        for j in range(i):\n",
    "            eval_features, eval_targets = eval_features_cache[j]\n",
    "            predictions = predict_lwp(eval_features, prototypes)\n",
    "            accuracy= accuracy_score(eval_targets, predictions)\n",
    "            accuracies[i - 1, j] = accuracy\n",
    "            print(f\"Evaluation with Eval {j+1} for F {i}: {accuracy}\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "    return accuracies,models[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7A8HUEdwVZA4",
    "outputId": "e6d1c2ba-43b7-4526-ba78-7f9aa0cbbde2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working for f1\n",
      "Evaluation with Eval 1 for F 1: 0.8856\n",
      "\n",
      "\n",
      "Working for f2\n",
      "Evaluation with Eval 1 for F 2: 0.8772\n",
      "Evaluation with Eval 2 for F 2: 0.8896\n",
      "\n",
      "\n",
      "Working for f3\n",
      "Evaluation with Eval 1 for F 3: 0.8744\n",
      "Evaluation with Eval 2 for F 3: 0.8856\n",
      "Evaluation with Eval 3 for F 3: 0.8816\n",
      "\n",
      "\n",
      "Working for f4\n",
      "Evaluation with Eval 1 for F 4: 0.8744\n",
      "Evaluation with Eval 2 for F 4: 0.886\n",
      "Evaluation with Eval 3 for F 4: 0.8808\n",
      "Evaluation with Eval 4 for F 4: 0.8868\n",
      "\n",
      "\n",
      "Working for f5\n",
      "Evaluation with Eval 1 for F 5: 0.874\n",
      "Evaluation with Eval 2 for F 5: 0.8816\n",
      "Evaluation with Eval 3 for F 5: 0.8776\n",
      "Evaluation with Eval 4 for F 5: 0.8868\n",
      "Evaluation with Eval 5 for F 5: 0.8888\n",
      "\n",
      "\n",
      "Working for f6\n",
      "Evaluation with Eval 1 for F 6: 0.8736\n",
      "Evaluation with Eval 2 for F 6: 0.88\n",
      "Evaluation with Eval 3 for F 6: 0.874\n",
      "Evaluation with Eval 4 for F 6: 0.884\n",
      "Evaluation with Eval 5 for F 6: 0.886\n",
      "Evaluation with Eval 6 for F 6: 0.8804\n",
      "\n",
      "\n",
      "Working for f7\n",
      "Evaluation with Eval 1 for F 7: 0.8732\n",
      "Evaluation with Eval 2 for F 7: 0.8836\n",
      "Evaluation with Eval 3 for F 7: 0.8736\n",
      "Evaluation with Eval 4 for F 7: 0.884\n",
      "Evaluation with Eval 5 for F 7: 0.8872\n",
      "Evaluation with Eval 6 for F 7: 0.8792\n",
      "Evaluation with Eval 7 for F 7: 0.8736\n",
      "\n",
      "\n",
      "Working for f8\n",
      "Evaluation with Eval 1 for F 8: 0.8696\n",
      "Evaluation with Eval 2 for F 8: 0.8792\n",
      "Evaluation with Eval 3 for F 8: 0.8716\n",
      "Evaluation with Eval 4 for F 8: 0.8828\n",
      "Evaluation with Eval 5 for F 8: 0.8852\n",
      "Evaluation with Eval 6 for F 8: 0.8768\n",
      "Evaluation with Eval 7 for F 8: 0.8732\n",
      "Evaluation with Eval 8 for F 8: 0.8728\n",
      "\n",
      "\n",
      "Working for f9\n",
      "Evaluation with Eval 1 for F 9: 0.87\n",
      "Evaluation with Eval 2 for F 9: 0.8796\n",
      "Evaluation with Eval 3 for F 9: 0.8716\n",
      "Evaluation with Eval 4 for F 9: 0.8824\n",
      "Evaluation with Eval 5 for F 9: 0.8856\n",
      "Evaluation with Eval 6 for F 9: 0.8784\n",
      "Evaluation with Eval 7 for F 9: 0.874\n",
      "Evaluation with Eval 8 for F 9: 0.8744\n",
      "Evaluation with Eval 9 for F 9: 0.872\n",
      "\n",
      "\n",
      "Working for f10\n",
      "Evaluation with Eval 1 for F 10: 0.8688\n",
      "Evaluation with Eval 2 for F 10: 0.8796\n",
      "Evaluation with Eval 3 for F 10: 0.8716\n",
      "Evaluation with Eval 4 for F 10: 0.8796\n",
      "Evaluation with Eval 5 for F 10: 0.8824\n",
      "Evaluation with Eval 6 for F 10: 0.8764\n",
      "Evaluation with Eval 7 for F 10: 0.872\n",
      "Evaluation with Eval 8 for F 10: 0.8744\n",
      "Evaluation with Eval 9 for F 10: 0.8716\n",
      "Evaluation with Eval 10 for F 10: 0.8844\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "       D1      D2      D3      D4      D5      D6      D7      D8      D9    \\\n",
      "f1   0.8856                                                                   \n",
      "f2   0.8772  0.8896                                                           \n",
      "f3   0.8744  0.8856  0.8816                                                   \n",
      "f4   0.8744  0.8860  0.8808  0.8868                                           \n",
      "f5   0.8740  0.8816  0.8776  0.8868  0.8888                                   \n",
      "f6   0.8736  0.8800  0.8740  0.8840  0.8860  0.8804                           \n",
      "f7   0.8732  0.8836  0.8736  0.8840  0.8872  0.8792  0.8736                   \n",
      "f8   0.8696  0.8792  0.8716  0.8828  0.8852  0.8768  0.8732  0.8728           \n",
      "f9   0.8700  0.8796  0.8716  0.8824  0.8856  0.8784  0.8740  0.8744  0.8720   \n",
      "f10  0.8688  0.8796  0.8716  0.8796  0.8824  0.8764  0.8720  0.8744  0.8716   \n",
      "\n",
      "      D10    \n",
      "f1           \n",
      "f2           \n",
      "f3           \n",
      "f4           \n",
      "f5           \n",
      "f6           \n",
      "f7           \n",
      "f8           \n",
      "f9           \n",
      "f10  0.8844  \n"
     ]
    }
   ],
   "source": [
    "# Dataset paths\n",
    "train_paths = [\n",
    "    f\"dataset/part_one_dataset/train_data/{i}_train_data.tar.pth\" for i in range(1, 11)\n",
    "]\n",
    "eval_paths = [\n",
    "    f\"dataset/part_one_dataset/eval_data/{i}_eval_data.tar.pth\" for i in range(1, 11)\n",
    "]\n",
    "\n",
    "# features_cache = torch.load(\"/content/drive/MyDrive/dataset/features_cache1.pth\")\n",
    "# eval_features_cache = torch.load(\"/content/drive/MyDrive/dataset/eval_features_cache1.pth\")\n",
    "features_cache = torch.load(\"features_cache1.pth\")\n",
    "eval_features_cache = torch.load(\"eval_features_cache1.pth\")\n",
    "\n",
    "\n",
    "# Task 1\n",
    "accuracies,f10 = task1(train_paths, eval_paths,features_cache,eval_features_cache)\n",
    "\n",
    "\n",
    "# Display the accuracy matrix\n",
    "import pandas as pd\n",
    "accuracy_df = pd.DataFrame(\n",
    "    accuracies,\n",
    "    columns=[f\"D{i}\" for i in range(1, 11)],\n",
    "    index=[f\"f{i}\" for i in range(1, 11)]\n",
    ")\n",
    "accuracy_df = accuracy_df.where(abs(accuracy_df) > 1e-4, other=pd.NA)\n",
    "accuracy_df = accuracy_df.fillna(\"\")\n",
    "print(\"\\n\")\n",
    "pd.set_option(\"display.colheader_justify\", \"center\")  # Center column headers\n",
    "pd.set_option(\"display.width\", None)  # Allow the full width to be displayed\n",
    "pd.set_option(\"display.float_format\", \"{: .4f}\".format)  # Set float format to 4 decimal places\n",
    "print(accuracy_df)\n",
    "\n",
    "# Saving the maodel F10 to use in task 2\n",
    "torch.save(f10, \"f10.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
