{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mw6Ig2Bcjn8r"
   },
   "source": [
    "## Group 36 - Task 2\n",
    "\n",
    "### Paths to change\n",
    "1. train_paths and eval_paths in cell 4 with dataset paths properly\n",
    "2. train_paths, eval_paths, feature_cache.pth, eval_feature_cache.pth,f10.pth paths in cell 6 with dataset paths properly\n",
    "\n",
    "feature_cache2.pth and eval_feature_cache2.pth files will be generated by feature extraction in cell4.\n",
    "\n",
    "We have explicitly provided link to these files to use directly avoiding cell4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQ7KDNbLY33v",
    "outputId": "cbc00536-d4f1-42c6-a93c-c0b9c45f1f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.models import efficientnet_b3\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torchvision.models import efficientnet_b3\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "print(\"All packages imported successfully!\")\n",
    "import warnings\n",
    "# Suppress specific warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.utils.data.dataloader\")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=r\"You are using `torch.load` with `weights_only=False`.*\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1uE-zL1Y6Cl",
    "outputId": "50fc51c4-363a-4616-f982-9170e58c7b77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ceJjYxX1Y8bu"
   },
   "outputs": [],
   "source": [
    "# Feature Extractor - EfficientNet_B3\n",
    "\n",
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "\n",
    "# EfficientNet feature extractor\n",
    "def initialize_feature_extractor():\n",
    "    # model = efficientnet_b3(pretrained=True)\n",
    "    model = efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "# Extract features using EfficientNet\n",
    "def extract_features(data, feature_extractor, batch_size=32):\n",
    "    transform = get_transform()\n",
    "    images = data['data']  # Assumed to be a numpy array\n",
    "    labels = torch.tensor(data['targets']) if 'targets' in data else None\n",
    "    transformed_images = [transform(Image.fromarray(img)) for img in images]\n",
    "    transformed_images = torch.stack(transformed_images)  # Stack them into a tensor\n",
    "\n",
    "    # dataset = TensorDataset(transformed_images, labels)  # TensorDataset\n",
    "    if labels is not None:\n",
    "        dataset = TensorDataset(transformed_images, labels)  # Dataset with images and labels\n",
    "    else:\n",
    "        dataset = TensorDataset(transformed_images)  # Dataset with images only\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch  in tqdm(dataloader, desc=\"Extracting Features \"):\n",
    "            if labels is not None:\n",
    "                images, batch_labels = batch\n",
    "                all_labels.append(batch_labels)  # Collect labels\n",
    "            else:\n",
    "                images = batch[0]\n",
    "            images = images.to(device)\n",
    "            feats = feature_extractor(images).view(feature_extractor(images).size(0), -1)  # Flatten the features\n",
    "            features.append(feats.cpu().numpy())\n",
    "            # labels.append(_.cpu())\n",
    "    features = np.concatenate(features)\n",
    "    all_labels = np.concatenate(all_labels) if labels is not None else None\n",
    "    return features, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Imc6KhTZc1s",
    "outputId": "c77d92f4-fe60-475a-d922-dd93c833a0a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for training dataset D11 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for training dataset D12 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:12<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for training dataset D13 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:12<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for training dataset D14 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for training dataset D15 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for training dataset D16 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for training dataset D17 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for training dataset D18 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for training dataset D19 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for training dataset D20 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D1 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D2 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D3 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D4 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D5 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D6 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D7 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D8 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D9 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D10 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D11 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D12 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D13 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D14 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D15 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D16 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D17 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D18 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D19 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing features for Eval dataset D20 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features : 100%|██████████| 79/79 [00:13<00:00,  5.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction - Will save 2 files features_cache1.pth and eval_features_cache1.pth\n",
    "# These files will be later imported by our code\n",
    "\n",
    "# We have already provided the extracted features and can use them directly skipping this cell\n",
    "\n",
    "\n",
    "\n",
    "features_cache = {}\n",
    "eval_features_cache = {}\n",
    "\n",
    "train_paths = [\n",
    "    f\"dataset/part_two_dataset/train_data/{i}_train_data.tar.pth\" for i in range(1, 11)\n",
    "]\n",
    "eval_paths = [\n",
    "     f\"dataset/part_one_dataset/eval_data/{i}_eval_data.tar.pth\" for i in range(1, 11)\n",
    "] + [\n",
    "    f\"dataset/part_two_dataset/eval_data/{i}_eval_data.tar.pth\" for i in range(1, 11)\n",
    "]\n",
    "\n",
    "feature_extractor = initialize_feature_extractor()\n",
    "\n",
    "for i in range(10):\n",
    "  print(f\"Precomputing features for training dataset D{i+11} : \")\n",
    "  if i not in features_cache:\n",
    "    current_data = torch.load(train_paths[i])\n",
    "    current_features,current_targets = extract_features(current_data, feature_extractor)\n",
    "    features_cache[i] = (current_features, current_targets)  # Cache features for the dataset\n",
    "\n",
    "for j in range(20):\n",
    "  print(f\"Precomputing features for Eval dataset D{j+1} : \")\n",
    "  if j not in eval_features_cache:\n",
    "    eval_data = torch.load(eval_paths[j])\n",
    "    eval_features,eval_targets = extract_features(eval_data, feature_extractor)\n",
    "    eval_features_cache[j] = (eval_features, eval_targets)\n",
    "\n",
    "# Save the features_cache and eval_features_cache\n",
    "torch.save(features_cache, \"features_cache2.pth\")\n",
    "torch.save(eval_features_cache, \"eval_features_cache2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YVW9wfTcZjSX"
   },
   "outputs": [],
   "source": [
    "def update_lwp(features, labels, last_model=None):\n",
    "    if last_model is None:\n",
    "      prototypes = {}\n",
    "      class_counts ={}\n",
    "    else:\n",
    "      prototypes = last_model[0]\n",
    "      class_counts = last_model[1]\n",
    "\n",
    "    # Iterate over each unique class in the current dataset\n",
    "    classes = np.unique(labels)\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "\n",
    "\n",
    "    for cls in classes:\n",
    "        # Get the indices of the samples belonging to this class\n",
    "        class_indices = np.where(labels == cls)[0]\n",
    "\n",
    "        # Calculate the mean of the features for this class\n",
    "        class_features = features[class_indices]\n",
    "\n",
    "        weight = class_weights[np.where(classes == cls)[0][0]]  # Get the weight for this class\n",
    "        weighted_features = class_features * weight  # Weight each feature vector by its class weight\n",
    "        new_mean = class_features.mean(axis=0)\n",
    "\n",
    "        # Update the prototypes using weighted averaging\n",
    "        if cls in prototypes:\n",
    "            # Existing prototype (weighted average update)\n",
    "            old_prototype = prototypes[cls]\n",
    "            old_count = class_counts[cls]\n",
    "            new_count = len(class_indices)\n",
    "\n",
    "            updated_prototype = (old_prototype * old_count + new_mean * new_count) / (old_count + new_count)\n",
    "            prototypes[cls] = updated_prototype\n",
    "            class_counts[cls] += new_count  # Update the count of samples for this class\n",
    "        else:\n",
    "        # If it's the first time this class is seen, just store the new mean\n",
    "            prototypes[cls] = new_mean\n",
    "            class_counts[cls] = len(class_indices)  # Set the count of samples for this class\n",
    "\n",
    "    return prototypes, class_counts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict using the Nearest Mean Classifier\n",
    "def predict_lwp(features, prototypes):\n",
    "    distances = np.stack([np.linalg.norm(features - proto, axis=1) for proto in prototypes.values()], axis=1)\n",
    "    return np.argmin(distances, axis=1)\n",
    "\n",
    "# Self-training process\n",
    "def task2(train_paths, eval_paths,start_model,features_cache,eval_features_cache):\n",
    "    accuracies = np.zeros((10, 20))  # Accuracy matrix (10x20)\n",
    "\n",
    "    prototypes, class_counts = start_model\n",
    "\n",
    "    models=[]\n",
    "    models.append(start_model)\n",
    "\n",
    "\n",
    "    # Predicting for all other datasets (D11, D12, ..., D20) and updating LwP\n",
    "    for i in range(10):\n",
    "        print(f\"Working for f{i+11}\")\n",
    "\n",
    "        # Loading and Feature Extraction od Dataset i\n",
    "        current_features, current_targets = features_cache[i]\n",
    "\n",
    "        predicted_labels = predict_lwp(current_features, prototypes)\n",
    "        prototypes, class_counts = update_lwp(current_features, predicted_labels, models[-1])\n",
    "        models.append((prototypes,class_counts))\n",
    "\n",
    "        # Evaluate the model on all relevant held-out datasets\n",
    "        for j in range(i+11):\n",
    "            eval_features, eval_targets = eval_features_cache[j]\n",
    "            predictions = predict_lwp(eval_features, prototypes)\n",
    "            accuracy= accuracy_score(eval_targets, predictions)\n",
    "            accuracies[i, j] = accuracy\n",
    "            print(f\"Evaluation with Eval {j+1} for F {i+11}: {accuracy} \")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3WhTCnYaC9_",
    "outputId": "2fe8e50e-e9e9-4b3b-f046-18364dd9350b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working for f11\n",
      "Evaluation with Eval 1 for F 11: 0.8696 \n",
      "Evaluation with Eval 2 for F 11: 0.8792 \n",
      "Evaluation with Eval 3 for F 11: 0.8712 \n",
      "Evaluation with Eval 4 for F 11: 0.8772 \n",
      "Evaluation with Eval 5 for F 11: 0.8824 \n",
      "Evaluation with Eval 6 for F 11: 0.8752 \n",
      "Evaluation with Eval 7 for F 11: 0.8716 \n",
      "Evaluation with Eval 8 for F 11: 0.872 \n",
      "Evaluation with Eval 9 for F 11: 0.8712 \n",
      "Evaluation with Eval 10 for F 11: 0.886 \n",
      "Evaluation with Eval 11 for F 11: 0.724 \n",
      "\n",
      "\n",
      "Working for f12\n",
      "Evaluation with Eval 1 for F 12: 0.8656 \n",
      "Evaluation with Eval 2 for F 12: 0.878 \n",
      "Evaluation with Eval 3 for F 12: 0.8676 \n",
      "Evaluation with Eval 4 for F 12: 0.8772 \n",
      "Evaluation with Eval 5 for F 12: 0.8792 \n",
      "Evaluation with Eval 6 for F 12: 0.8736 \n",
      "Evaluation with Eval 7 for F 12: 0.8684 \n",
      "Evaluation with Eval 8 for F 12: 0.87 \n",
      "Evaluation with Eval 9 for F 12: 0.8676 \n",
      "Evaluation with Eval 10 for F 12: 0.882 \n",
      "Evaluation with Eval 11 for F 12: 0.7212 \n",
      "Evaluation with Eval 12 for F 12: 0.4752 \n",
      "\n",
      "\n",
      "Working for f13\n",
      "Evaluation with Eval 1 for F 13: 0.864 \n",
      "Evaluation with Eval 2 for F 13: 0.878 \n",
      "Evaluation with Eval 3 for F 13: 0.866 \n",
      "Evaluation with Eval 4 for F 13: 0.876 \n",
      "Evaluation with Eval 5 for F 13: 0.8776 \n",
      "Evaluation with Eval 6 for F 13: 0.8716 \n",
      "Evaluation with Eval 7 for F 13: 0.8676 \n",
      "Evaluation with Eval 8 for F 13: 0.868 \n",
      "Evaluation with Eval 9 for F 13: 0.866 \n",
      "Evaluation with Eval 10 for F 13: 0.88 \n",
      "Evaluation with Eval 11 for F 13: 0.7196 \n",
      "Evaluation with Eval 12 for F 13: 0.4744 \n",
      "Evaluation with Eval 13 for F 13: 0.78 \n",
      "\n",
      "\n",
      "Working for f14\n",
      "Evaluation with Eval 1 for F 14: 0.8636 \n",
      "Evaluation with Eval 2 for F 14: 0.878 \n",
      "Evaluation with Eval 3 for F 14: 0.8668 \n",
      "Evaluation with Eval 4 for F 14: 0.876 \n",
      "Evaluation with Eval 5 for F 14: 0.8772 \n",
      "Evaluation with Eval 6 for F 14: 0.8712 \n",
      "Evaluation with Eval 7 for F 14: 0.8676 \n",
      "Evaluation with Eval 8 for F 14: 0.8676 \n",
      "Evaluation with Eval 9 for F 14: 0.8656 \n",
      "Evaluation with Eval 10 for F 14: 0.8808 \n",
      "Evaluation with Eval 11 for F 14: 0.7212 \n",
      "Evaluation with Eval 12 for F 14: 0.4748 \n",
      "Evaluation with Eval 13 for F 14: 0.7792 \n",
      "Evaluation with Eval 14 for F 14: 0.8528 \n",
      "\n",
      "\n",
      "Working for f15\n",
      "Evaluation with Eval 1 for F 15: 0.8632 \n",
      "Evaluation with Eval 2 for F 15: 0.876 \n",
      "Evaluation with Eval 3 for F 15: 0.868 \n",
      "Evaluation with Eval 4 for F 15: 0.8764 \n",
      "Evaluation with Eval 5 for F 15: 0.8772 \n",
      "Evaluation with Eval 6 for F 15: 0.8712 \n",
      "Evaluation with Eval 7 for F 15: 0.8672 \n",
      "Evaluation with Eval 8 for F 15: 0.8672 \n",
      "Evaluation with Eval 9 for F 15: 0.8652 \n",
      "Evaluation with Eval 10 for F 15: 0.8808 \n",
      "Evaluation with Eval 11 for F 15: 0.7208 \n",
      "Evaluation with Eval 12 for F 15: 0.476 \n",
      "Evaluation with Eval 13 for F 15: 0.7796 \n",
      "Evaluation with Eval 14 for F 15: 0.8528 \n",
      "Evaluation with Eval 15 for F 15: 0.8636 \n",
      "\n",
      "\n",
      "Working for f16\n",
      "Evaluation with Eval 1 for F 16: 0.8624 \n",
      "Evaluation with Eval 2 for F 16: 0.8748 \n",
      "Evaluation with Eval 3 for F 16: 0.866 \n",
      "Evaluation with Eval 4 for F 16: 0.8756 \n",
      "Evaluation with Eval 5 for F 16: 0.8756 \n",
      "Evaluation with Eval 6 for F 16: 0.8704 \n",
      "Evaluation with Eval 7 for F 16: 0.8656 \n",
      "Evaluation with Eval 8 for F 16: 0.8656 \n",
      "Evaluation with Eval 9 for F 16: 0.8644 \n",
      "Evaluation with Eval 10 for F 16: 0.8804 \n",
      "Evaluation with Eval 11 for F 16: 0.7204 \n",
      "Evaluation with Eval 12 for F 16: 0.4752 \n",
      "Evaluation with Eval 13 for F 16: 0.7776 \n",
      "Evaluation with Eval 14 for F 16: 0.852 \n",
      "Evaluation with Eval 15 for F 16: 0.8616 \n",
      "Evaluation with Eval 16 for F 16: 0.7284 \n",
      "\n",
      "\n",
      "Working for f17\n",
      "Evaluation with Eval 1 for F 17: 0.8628 \n",
      "Evaluation with Eval 2 for F 17: 0.8748 \n",
      "Evaluation with Eval 3 for F 17: 0.8664 \n",
      "Evaluation with Eval 4 for F 17: 0.8752 \n",
      "Evaluation with Eval 5 for F 17: 0.8748 \n",
      "Evaluation with Eval 6 for F 17: 0.8692 \n",
      "Evaluation with Eval 7 for F 17: 0.866 \n",
      "Evaluation with Eval 8 for F 17: 0.8644 \n",
      "Evaluation with Eval 9 for F 17: 0.8644 \n",
      "Evaluation with Eval 10 for F 17: 0.878 \n",
      "Evaluation with Eval 11 for F 17: 0.7192 \n",
      "Evaluation with Eval 12 for F 17: 0.4752 \n",
      "Evaluation with Eval 13 for F 17: 0.776 \n",
      "Evaluation with Eval 14 for F 17: 0.8516 \n",
      "Evaluation with Eval 15 for F 17: 0.8608 \n",
      "Evaluation with Eval 16 for F 17: 0.7284 \n",
      "Evaluation with Eval 17 for F 17: 0.7928 \n",
      "\n",
      "\n",
      "Working for f18\n",
      "Evaluation with Eval 1 for F 18: 0.8612 \n",
      "Evaluation with Eval 2 for F 18: 0.872 \n",
      "Evaluation with Eval 3 for F 18: 0.8652 \n",
      "Evaluation with Eval 4 for F 18: 0.8744 \n",
      "Evaluation with Eval 5 for F 18: 0.8744 \n",
      "Evaluation with Eval 6 for F 18: 0.8692 \n",
      "Evaluation with Eval 7 for F 18: 0.8644 \n",
      "Evaluation with Eval 8 for F 18: 0.8624 \n",
      "Evaluation with Eval 9 for F 18: 0.8636 \n",
      "Evaluation with Eval 10 for F 18: 0.8772 \n",
      "Evaluation with Eval 11 for F 18: 0.7188 \n",
      "Evaluation with Eval 12 for F 18: 0.4736 \n",
      "Evaluation with Eval 13 for F 18: 0.7756 \n",
      "Evaluation with Eval 14 for F 18: 0.8512 \n",
      "Evaluation with Eval 15 for F 18: 0.862 \n",
      "Evaluation with Eval 16 for F 18: 0.7276 \n",
      "Evaluation with Eval 17 for F 18: 0.792 \n",
      "Evaluation with Eval 18 for F 18: 0.7556 \n",
      "\n",
      "\n",
      "Working for f19\n",
      "Evaluation with Eval 1 for F 19: 0.8604 \n",
      "Evaluation with Eval 2 for F 19: 0.8712 \n",
      "Evaluation with Eval 3 for F 19: 0.8652 \n",
      "Evaluation with Eval 4 for F 19: 0.8756 \n",
      "Evaluation with Eval 5 for F 19: 0.8744 \n",
      "Evaluation with Eval 6 for F 19: 0.8688 \n",
      "Evaluation with Eval 7 for F 19: 0.8636 \n",
      "Evaluation with Eval 8 for F 19: 0.8616 \n",
      "Evaluation with Eval 9 for F 19: 0.8628 \n",
      "Evaluation with Eval 10 for F 19: 0.8768 \n",
      "Evaluation with Eval 11 for F 19: 0.7164 \n",
      "Evaluation with Eval 12 for F 19: 0.4736 \n",
      "Evaluation with Eval 13 for F 19: 0.7748 \n",
      "Evaluation with Eval 14 for F 19: 0.8524 \n",
      "Evaluation with Eval 15 for F 19: 0.8616 \n",
      "Evaluation with Eval 16 for F 19: 0.7272 \n",
      "Evaluation with Eval 17 for F 19: 0.7928 \n",
      "Evaluation with Eval 18 for F 19: 0.7548 \n",
      "Evaluation with Eval 19 for F 19: 0.6544 \n",
      "\n",
      "\n",
      "Working for f20\n",
      "Evaluation with Eval 1 for F 20: 0.86 \n",
      "Evaluation with Eval 2 for F 20: 0.8708 \n",
      "Evaluation with Eval 3 for F 20: 0.8656 \n",
      "Evaluation with Eval 4 for F 20: 0.8756 \n",
      "Evaluation with Eval 5 for F 20: 0.8736 \n",
      "Evaluation with Eval 6 for F 20: 0.868 \n",
      "Evaluation with Eval 7 for F 20: 0.8636 \n",
      "Evaluation with Eval 8 for F 20: 0.8612 \n",
      "Evaluation with Eval 9 for F 20: 0.8624 \n",
      "Evaluation with Eval 10 for F 20: 0.8764 \n",
      "Evaluation with Eval 11 for F 20: 0.7184 \n",
      "Evaluation with Eval 12 for F 20: 0.474 \n",
      "Evaluation with Eval 13 for F 20: 0.7752 \n",
      "Evaluation with Eval 14 for F 20: 0.8524 \n",
      "Evaluation with Eval 15 for F 20: 0.8608 \n",
      "Evaluation with Eval 16 for F 20: 0.726 \n",
      "Evaluation with Eval 17 for F 20: 0.7924 \n",
      "Evaluation with Eval 18 for F 20: 0.7532 \n",
      "Evaluation with Eval 19 for F 20: 0.6536 \n",
      "Evaluation with Eval 20 for F 20: 0.844 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "       D1      D2      D3      D4      D5      D6      D7      D8      D9    \\\n",
      "f11  0.8696  0.8792  0.8712  0.8772  0.8824  0.8752  0.8716  0.8720  0.8712   \n",
      "f12  0.8656  0.8780  0.8676  0.8772  0.8792  0.8736  0.8684  0.8700  0.8676   \n",
      "f13  0.8640  0.8780  0.8660  0.8760  0.8776  0.8716  0.8676  0.8680  0.8660   \n",
      "f14  0.8636  0.8780  0.8668  0.8760  0.8772  0.8712  0.8676  0.8676  0.8656   \n",
      "f15  0.8632  0.8760  0.8680  0.8764  0.8772  0.8712  0.8672  0.8672  0.8652   \n",
      "f16  0.8624  0.8748  0.8660  0.8756  0.8756  0.8704  0.8656  0.8656  0.8644   \n",
      "f17  0.8628  0.8748  0.8664  0.8752  0.8748  0.8692  0.8660  0.8644  0.8644   \n",
      "f18  0.8612  0.8720  0.8652  0.8744  0.8744  0.8692  0.8644  0.8624  0.8636   \n",
      "f19  0.8604  0.8712  0.8652  0.8756  0.8744  0.8688  0.8636  0.8616  0.8628   \n",
      "f20  0.8600  0.8708  0.8656  0.8756  0.8736  0.8680  0.8636  0.8612  0.8624   \n",
      "\n",
      "       D10     D11    D12     D13     D14     D15     D16     D17     D18    \\\n",
      "f11  0.8860  0.7240                                                           \n",
      "f12  0.8820  0.7212  0.4752                                                   \n",
      "f13  0.8800  0.7196  0.4744  0.7800                                           \n",
      "f14  0.8808  0.7212  0.4748  0.7792  0.8528                                   \n",
      "f15  0.8808  0.7208  0.4760  0.7796  0.8528  0.8636                           \n",
      "f16  0.8804  0.7204  0.4752  0.7776  0.8520  0.8616  0.7284                   \n",
      "f17  0.8780  0.7192  0.4752  0.7760  0.8516  0.8608  0.7284  0.7928           \n",
      "f18  0.8772  0.7188  0.4736  0.7756  0.8512  0.8620  0.7276  0.7920  0.7556   \n",
      "f19  0.8768  0.7164  0.4736  0.7748  0.8524  0.8616  0.7272  0.7928  0.7548   \n",
      "f20  0.8764  0.7184  0.4740  0.7752  0.8524  0.8608  0.7260  0.7924  0.7532   \n",
      "\n",
      "      D19     D20    \n",
      "f11                  \n",
      "f12                  \n",
      "f13                  \n",
      "f14                  \n",
      "f15                  \n",
      "f16                  \n",
      "f17                  \n",
      "f18                  \n",
      "f19  0.6544          \n",
      "f20  0.6536  0.8440  \n"
     ]
    }
   ],
   "source": [
    "# Dataset paths\n",
    "train_paths = [\n",
    "    f\"dataset/part_two_dataset/train_data/{i}_train_data.tar.pth\" for i in range(1, 11)\n",
    "]\n",
    "eval_paths = [\n",
    "     f\"dataset/part_one_dataset/eval_data/{i}_eval_data.tar.pth\" for i in range(1, 11)\n",
    "] + [\n",
    "    f\"dataset/part_two_dataset/eval_data/{i}_eval_data.tar.pth\" for i in range(1, 11)\n",
    "]\n",
    "\n",
    "f10 = torch.load(\"f10.pth\")\n",
    "features_cache = torch.load(\"features_cache2.pth\")\n",
    "eval_features_cache = torch.load(\"eval_features_cache2.pth\")\n",
    "\n",
    "\n",
    "# Run the Task2\n",
    "accuracies = task2(train_paths, eval_paths,f10,features_cache,eval_features_cache)\n",
    "\n",
    "\n",
    "# Display the accuracy matrix\n",
    "import pandas as pd\n",
    "accuracy_df = pd.DataFrame(\n",
    "    accuracies,\n",
    "    columns=[f\"D{i}\" for i in range(1, 21)],\n",
    "    index=[f\"f{i}\" for i in range(11, 21)]\n",
    ")\n",
    "accuracy_df = accuracy_df.where(abs(accuracy_df) > 1e-4, other=pd.NA)\n",
    "accuracy_df = accuracy_df.fillna(\"\")\n",
    "\n",
    "print(\"\\n\")\n",
    "pd.set_option(\"display.colheader_justify\", \"center\")  # Center column headers\n",
    "pd.set_option(\"display.width\", None)  # Allow the full width to be displayed\n",
    "pd.set_option(\"display.float_format\", \"{: .4f}\".format)  # Set float format to 4 decimal places\n",
    "print(accuracy_df)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
